# 레디스 운영 고려사항

## 임계점

- 스케일 업으로 장치 한 대의 성능 향상시키는 것에는 한계가 금방 찾아옴
- 스케일 아웃은 논리적으로는 한계가 없으나 실제로는 네트워크 대역폭 등의 한계 존재

### CPU

- 레디스는 단일 스레드이므로 멀티 코어 환경에서도 하나의 코어만 사용
- 단일 코어의 성능이 높을 수록 유리
- 레디스가 사용하는 하나의 코어만 사용률이 100%가까이 됨

### 메모리 대역폭

- 1초에 전송할 수 있는 데이터의 양
- 하나의 하드웨어에서 많은 레디스 인스턴스를 사용하는 경우
  - 많은 인스턴스들이 메모리 대역폭을 공유
  - 메모리 대역폭을 통해 데이터 버스로 CPU와 통하는 데이터 전송에 병목현상 발생

***

## 메모리 크기

- `redis.conf`의 `maxmemory`설정
  - 지정된 크기는 키, 데이터를 위한 공간 모두를 포함
  - 레디스가 데이터를 저장하기 위한 부가적인 데이터의 크기도 포함
- `maxmemory`설정을 하지 않을 경우
  - 레디스에 데이터가 계속 쌓여 물리 메모리를 모두 사용
  - 물리 메모리 보다 더 많은 양을 사용하려 할 경우 OS가 `Swap`을 통한 가상 메모리 할당
  - 하드디스크에 마련된 스왑공간을 이용하기 때문에 느려짐
  - 스왑 영역마저 충분하지 않으면 `OOM(Out of Memory) killer`를 통해 레디스가 종료됨
  - 시스템에 설치된 물리 메모리에 따라 알맞게 스왑 공간을 설정해야함
- `maxmemory`값 설정 후 지정한 메모리 크기 보다 많은 양의 쓰기가 발생할 경우
  - 쓰기 요청만 실패하고 읽기 요청을 정상처리됨
  - 레디스는 저장 가능한 메모리 영역을 확보하기 위해 기존 데이터를 지움
    - `redis.conf`의 `maxmemory-policy` 설정 정책에 따라 지움

***

## 네트워크

- 여러 노드로 구성된 클러스터에서 사용하는 네트워크 하드웨어에 따라 한계발생 가능성 존재
- 여러 노드가 연결된 네트워크 허브와 각 노드에 설치된 네트워크 카드의 속도에 관련
  - 연결된 노드가 많아 데이터 처리 속도가 네트워크 허브의 속도를 초과할 경우 존재
  - 이런 경우 노드가 여러개지만 제대로 성능을 발휘하지 못하게 됨
- 마스터-슬레이브 모델에서 동기화 처리가 네트워크 대역폭을 대부분 차지하므로 이를 분리
  - 각 노드당 마스터-슬레이브 동기화용으로 별도의 네트워크 카드를 추가로 설치
  - 새롭게 추가된 네트워크 카드를 기준으로 각 노드를 연결하는 별도의 네트워크 허브 구축
  - 이를 통해 일반적인 쓰기, 읽기 연산을 처리하는 네트워크와 동기화 처리 네트워크 분리

```text
                   +---------------+
     ┌──────────── | Network Hub 1 | ───────────┐
     │             +---------------+            │
     │                  │    │                  │
     │              ┌───┘    └───┐              │
     │              │            │              │
192.168.2.51  192.168.2.52  192.168.2.53  192.168.2.54
  +------+      +------+      +------+      +------+
  | Node |      | Node |      | Node |      | Node |
  +------+      +------+      +------+      +------+
192.168.9.51  192.168.9.52  192.168.9.53  192.168.9.54
     │              │            │              │
     │              └───┐    ┌───┘              │
     │                  │    │                  │
     │             +---------------+            │
     └──────────── | Network Hub 2 | ───────────┘
                   +---------------+
```

***

## 메모리 설정

- 스냅샷, AOF를 사용하는 경우 레디스가 `fork` 함수를 호출
- 만약 `fork`함수를 실패할 경우 이후의 모든 쓰기 연산은 실패처리됨
- 일반적인 경우 `fork`함수로 생성된 프로세스는 부모 프로세스의 메모리를 바로 복사하지 않음
- 그럼에도 추가적인 메모리가 존재하지 않으면 `fork`가 실패하게 됨
  - `/etc/sysctl.conf`파일의 `vm.overcommit_memory=1` 옵션을 사용함으로써 해결 가능
  - `0` : 기본설정값, `malloc` 요청이 들어오면 요청된 크기의 물리 메모리 존재시에만 할당
  - `1` : `malloc` 요청이 들어오면 물리 메모리가 없더라도 성공 반환
    - 해당 크기의 스왑영역 존재시에만 성공
    - 자식 프로세스는 `COW`에 의하여 부모 프로세스의 메모리 페이지 테이블을 복사
    - `COW(Copy On Write)` : 두 프로세스가 동일 메모리 공간을 공유하다 한 쪽에서 메모리 변경이 일어날 경우 변경된 메모리 페이지만 다른 메모리 영역에 복사하는 방법
  - `2` : 사용중인 메모리 크기가 `스왑공간 + vm.overcommit_ratio * 물리메모리`이내에만 할당

***

## 마스터-슬레이브 스냅샷

- 마스터 노드의 스냅샷 기능이 꺼져있어도 슬레이브 노드 추가시 마스터 노드의 스냅샷 생성
- `redis.conf`의 `client-output-buffer-limit`
  - 복제를 위한 스냅샷 생성 후 스냅샷 데이터를 슬레이브 노드로 전송하기 위해 버퍼 사용
  - 이 버퍼의 크기가 지정된 크기보다 커지면 슬레이브 노드와의 연결을 끊음
  - 이후 슬레이브는 다시 마스터와 연결을 위해 접속 시도, 접속 후 마스터는 다시 스냅샷 생성
  - 반복적인 악순환으로 성능 저하를 유발함

***

## 가상화 환경과 fork 함수

- 스냅샷, AOF사용시 `fork`를 사용하므로 `fork` 비용이 낮은 OS를 사용할 필요 존재
- 레디스는 단일 스레드이므로 `fork`실행 중에는 다른 요청을 처리하지 못함
  - `fork`함수 후 생성된 자식 프로세스가 데이터를 저장하는건 별개 (다른 요청 처리 가능)
- `fork`비용이 비싼 `Xen` 플랫폼 사용 지양